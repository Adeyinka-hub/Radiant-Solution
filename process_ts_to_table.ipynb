{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_76 = ['2017-04-01', '2017-04-04', '2017-04-11', '2017-04-14',\n",
    "           '2017-04-21', '2017-04-24', '2017-05-01', '2017-05-04',\n",
    "           '2017-05-11', '2017-05-14', '2017-05-21', '2017-05-24',\n",
    "           '2017-05-31', '2017-06-03', '2017-06-10', '2017-06-13',\n",
    "           '2017-06-20', '2017-06-23', '2017-06-30', '2017-07-03',\n",
    "           '2017-07-05', '2017-07-08', '2017-07-10', '2017-07-13',\n",
    "           '2017-07-15', '2017-07-18', '2017-07-20', '2017-07-23',\n",
    "           '2017-07-25', '2017-07-28', '2017-07-30', '2017-08-02',\n",
    "           '2017-08-04', '2017-08-07', '2017-08-09', '2017-08-12',\n",
    "           '2017-08-14', '2017-08-17', '2017-08-19', '2017-08-22',\n",
    "           '2017-08-24', '2017-08-27', '2017-08-29', '2017-09-01',\n",
    "           '2017-09-06', '2017-09-08', '2017-09-11', '2017-09-18',\n",
    "           '2017-09-21', '2017-09-23', '2017-09-26', '2017-09-28',\n",
    "           '2017-10-01', '2017-10-03', '2017-10-06', '2017-10-08',\n",
    "           '2017-10-11', '2017-10-13', '2017-10-16', '2017-10-18',\n",
    "           '2017-10-21', '2017-10-23', '2017-10-26', '2017-10-28',\n",
    "           '2017-10-31', '2017-11-02', '2017-11-05', '2017-11-07',\n",
    "           '2017-11-10', '2017-11-12', '2017-11-15', '2017-11-17',\n",
    "           '2017-11-20', '2017-11-22', '2017-11-27', '2017-11-30']\n",
    "\n",
    "TRAIN_FEATURES = ['ndvi_mean', 'ndvi_median', 'savi_mean', 'savi_median', 'arvi_mean',\n",
    "                  'arvi_median', 'evi_mean', 'evi_median', 'gci_mean', 'gci_median',\n",
    "                  'sipi_mean', 'sipi_median', 'nbr_mean', 'nbr_median', 'ndwi_mean',\n",
    "                  'ndwi_median', 'deforest_mean', 'deforest_median', 'sr_mean',\n",
    "                  'sr_median', 'cl_green_mean', 'cl_green_median', 'cl_rededge_mean',\n",
    "                  'cl_rededge_median', 'recl_mean', 'recl_median', 'ndre_mean',\n",
    "                  'ndre_median', 'B01_mean', 'B01_median', 'B02_mean', 'B02_median',\n",
    "                  'B03_mean', 'B03_median', 'B04_mean', 'B04_median', 'B05_mean',\n",
    "                  'B05_median', 'B06_mean', 'B06_median', 'B07_mean', 'B07_median',\n",
    "                  'B08_mean', 'B08_median', 'B8A_mean', 'B8A_median', 'B09_mean',\n",
    "                  'B09_median', 'B11_mean', 'B11_median', 'B12_mean', 'B12_median']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data_):\n",
    "    \n",
    "    temp = data_.reset_index(drop=True).copy()\n",
    "    \n",
    "    temp.loc[temp.ndvi_mean < temp.ndvi_mean.quantile(0.1), TRAIN_FEATURES] = np.nan\n",
    "        \n",
    "#     for u in range(2):\n",
    "        \n",
    "#         for column in ['ndvi_mean', 'ndvi_median', 'savi_median', 'gci_mean']:\n",
    "#             shft = temp[column].shift(1)\n",
    "#             shft_back = temp[column].shift(-1)\n",
    "#             shft2 = temp[column].shift(2)\n",
    "#             shft_back2 = temp[column].shift(-2)\n",
    "            \n",
    "#             temp.loc[((temp[column] < shft)&(temp[column] < shft_back))\n",
    "#                      |((temp[column] < shft2)&(temp[column] < shft_back))\n",
    "#                      |((temp[column] < shft)&(temp[column] < shft_back2))\n",
    "#                      |((temp[column] < shft2)&(temp[column] < shft_back2)), TRAIN_FEATURES] = np.nan\n",
    "        \n",
    "#             for col in TRAIN_FEATURES:\n",
    "#                 try:\n",
    "#                     temp[col] = temp[col].interpolate('quadratic')\n",
    "#                 except:\n",
    "#                     temp[col] = temp[col].interpolate('linear')\n",
    "            \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1):\n",
    "\n",
    "#     data = pd.read_csv('train_data/train{}.csv'.format(i)).copy()\n",
    "#     field_ids76 = data.field_id.unique()\n",
    "    \n",
    "#     data76 = pd.DataFrame()\n",
    "    \n",
    "#     for fid in field_ids76:\n",
    "#         temp = pd.DataFrame()\n",
    "#         temp['date'] = date_76\n",
    "#         temp['field_id'] = fid\n",
    "#         temp['id'] = data[data.field_id == fid].id.values[0]\n",
    "#         temp['label'] = data[data.field_id == fid].label.values[0]\n",
    "#         data76 = pd.concat([data76, temp], ignore_index=True)\n",
    "        \n",
    "#     data = pd.merge(data76, data, on=['date', 'field_id', 'id', 'label'], how='left')\n",
    "    \n",
    "#     data_processed = pd.DataFrame()\n",
    "    \n",
    "#     for fid in tqdm(data.field_id.unique()):\n",
    "#         data_processed = pd.concat([data_processed, preprocess_data(data[data.field_id == fid])], ignore_index=True)\n",
    "        \n",
    "# #     data_processed.to_csv('processed_train_data/train{}.csv'.format(i), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature = TRAIN_FEATURES[5]\n",
    "# for feature in TRAIN_FEATURES:\n",
    "#     print(feature)\n",
    "#     data_processed[data_processed.field_id == 62334][feature].reset_index(drop=True).plot()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train(data_):\n",
    "\n",
    "    trainlists = []\n",
    "        \n",
    "    for fid in data_.field_id.unique():\n",
    "        \n",
    "        trainl = []\n",
    "        trainl.append(fid)\n",
    "        \n",
    "        temp = data_[data_.field_id == fid].copy()\n",
    "        trainl.append(temp.label.values[0])\n",
    "        \n",
    "        for column in TRAIN_FEATURES:\n",
    "            [trainl.append(x) for x in temp[column].values]\n",
    "                \n",
    "        trainlists.append(trainl)\n",
    "        \n",
    "    columns = ['field_id', 'label']\n",
    "    for par in TRAIN_FEATURES:\n",
    "        for i in range(1, 77):\n",
    "            columns.append('{}_{}'.format(par, i))\n",
    "            \n",
    "    return pd.DataFrame(trainlists, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_test(data_):\n",
    "\n",
    "    trainlists = []\n",
    "        \n",
    "    for fid in data_.field_id.unique():\n",
    "        \n",
    "        trainl = []\n",
    "        trainl.append(fid)\n",
    "        \n",
    "        temp = data_[data_.field_id == fid].copy()\n",
    "        \n",
    "        for column in TRAIN_FEATURES:\n",
    "            [trainl.append(x) for x in temp[column].values]\n",
    "                \n",
    "        trainlists.append(trainl)\n",
    "        \n",
    "    columns = ['field_id']\n",
    "    for par in TRAIN_FEATURES:\n",
    "        for i in range(1, 77):\n",
    "            columns.append('{}_{}'.format(par, i))\n",
    "            \n",
    "    return pd.DataFrame(trainlists, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 114/114 [06:35<00:00,  3.47s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(114)):\n",
    "\n",
    "    data = pd.read_csv('test_data/test{}.csv'.format(i)).copy()\n",
    "    field_ids76 = data.field_id.unique()\n",
    "    \n",
    "    data76 = pd.DataFrame()\n",
    "    \n",
    "    for fid in field_ids76:\n",
    "        temp = pd.DataFrame()\n",
    "        temp['date'] = date_76\n",
    "        temp['field_id'] = fid\n",
    "        temp['id'] = data[data.field_id == fid].id.values[0]\n",
    "        data76 = pd.concat([data76, temp], ignore_index=True)\n",
    "        \n",
    "    data = pd.merge(data76, data, on=['date', 'field_id', 'id'], how='left')\n",
    "    \n",
    "    data_processed = pd.DataFrame()\n",
    "    \n",
    "    for fid in data.field_id.unique():\n",
    "        data_processed = pd.concat([data_processed, preprocess_data(data[data.field_id == fid])], ignore_index=True)\n",
    "        \n",
    "    data_processed = make_test(data_processed)\n",
    "        \n",
    "    data_processed.to_csv('processed_test_data/test{}.csv'.format(i), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 265/265 [19:23<00:00,  4.39s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(265)):\n",
    "\n",
    "    data = pd.read_csv('train_data/train{}.csv'.format(i)).copy()\n",
    "    field_ids76 = data.field_id.unique()\n",
    "\n",
    "    data76 = pd.DataFrame()\n",
    "\n",
    "    for fid in field_ids76:\n",
    "        temp = pd.DataFrame()\n",
    "        temp['date'] = date_76\n",
    "        temp['field_id'] = fid\n",
    "        temp['id'] = data[data.field_id == fid].id.values[0]\n",
    "        temp['label'] = data[data.field_id == fid].label.values[0]\n",
    "        data76 = pd.concat([data76, temp], ignore_index=True)\n",
    "\n",
    "    data = pd.merge(data76, data, on=['date', 'field_id', 'id', 'label'], how='left')\n",
    "    \n",
    "    data_processed = pd.DataFrame()\n",
    "    \n",
    "    for fid in data.field_id.unique():\n",
    "        data_processed = pd.concat([data_processed, preprocess_data(data[data.field_id == fid])], ignore_index=True)\n",
    "\n",
    "    data_processed = make_train(data_processed)\n",
    "        \n",
    "    data_processed.to_csv('processed_train_data/train{}.csv'.format(i), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
